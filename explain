#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
explain - ä¸“ä¸º Kali/Ubuntu è®¾è®¡çš„å‘½ä»¤è¡Œè§£é‡Šå·¥å…·
æ”¯æŒå®‰å…¨ï¼ˆæ¸—é€æµ‹è¯•/CTF/çº¢é˜Ÿï¼‰ä¸é€šç”¨ï¼ˆè¿ç»´/ç®¡ç†ï¼‰åŒè§†è§’

ç”¨æ³•:
  explain <command>              # åŒæ—¶è¾“å‡ºå®‰å…¨ + é€šç”¨ä¸¤ç§è§†è§’
  explain -s <command>           # ä»…å®‰å…¨è§†è§’ï¼ˆæ¸—é€/CTF/PrivEscï¼‰
  explain -g <command>           # ä»…é€šç”¨è§†è§’ï¼ˆç³»ç»Ÿç®¡ç†/è¿ç»´ï¼‰
  explain -n <command>           # å¿½ç•¥ç¼“å­˜å¼ºåˆ¶é‡æ–°æŸ¥è¯¢
  explain --config               # è¿è¡Œé…ç½®å‘å¯¼
  explain --clear-cache          # æ¸…ç©ºæœ¬åœ°ç¼“å­˜

ç¤ºä¾‹:
  explain chmod u+s /bin/bash
  explain -s find / -perm -4000 2>/dev/null
  explain -g tar -czf backup.tar.gz /etc
  explain -sg nmap -sV -O 192.168.1.1
"""

import argparse
import json
import os
import sys
import hashlib
import shutil
import urllib.request
import urllib.error
from pathlib import Path
from typing import Optional, Dict, Any

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é…ç½®ç®¡ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CONFIG_DIR  = Path.home() / ".config" / "explain-tool"
CONFIG_FILE = CONFIG_DIR / "config.json"
CACHE_DIR   = CONFIG_DIR / "cache"

DEFAULT_CONFIG: Dict[str, Any] = {
    "backend":      "openai",        # openai | ollama | deepseek | custom
    "api_key":      "",
    "api_base":     "https://api.openai.com/v1",
    "model":        "gpt-4o-mini",
    "language":     "zh",            # zhï¼ˆä¸­æ–‡ï¼‰| enï¼ˆEnglishï¼‰
    "cache":        True,
    "ollama_host":  "http://localhost:11434",
    "ollama_model": "qwen2.5:7b",
}

SUPPORTED_LANGUAGES = {
    "zh": "ä¸­æ–‡",
    "en": "English",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æç¤ºè¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_BOTH = """\
ä½ æ˜¯ä¸€ååŒæ—¶ç²¾é€š Linux ç³»ç»Ÿç®¡ç†å’Œç½‘ç»œå®‰å…¨ï¼ˆæ¸—é€æµ‹è¯•/CTFï¼‰çš„ä¸“å®¶é¡¾é—®ã€‚
ç”¨æˆ·ä¼šç»™ä½ ä¸€æ¡ Linux/Kali å‘½ä»¤ï¼ˆå¯èƒ½å¸¦å‚æ•°å’Œç›®æ ‡è·¯å¾„ï¼‰ï¼Œè¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ Markdown ç»“æ„å›å¤ï¼š

## ğŸ“‹ å‘½ä»¤æ¦‚è§ˆ
ï¼ˆ1-2 å¥è¯æè¿°è¯¥å‘½ä»¤çš„æ ¸å¿ƒåŠŸèƒ½ï¼‰

## ğŸ”© å‚æ•°è§£æ
ï¼ˆç”¨è¡¨æ ¼æˆ–åˆ—è¡¨ï¼Œé€é¡¹è§£é‡Šå‘½ä»¤ä¸­çš„æ¯ä¸ªé€‰é¡¹ / å‚æ•° / ç›®æ ‡è·¯å¾„ï¼‰

## ğŸ”§ é€šç”¨è§†è§’
ï¼ˆä»ç³»ç»Ÿç®¡ç†ã€æ—¥å¸¸è¿ç»´ã€å¼€å‘è§’åº¦åˆ†æå…¸å‹ç”¨é€”ã€æ³¨æ„äº‹é¡¹ã€æœ€ä½³å®è·µï¼‰

## ğŸ”´ å®‰å…¨è§†è§’
ï¼ˆä»æ¸—é€æµ‹è¯• / æƒé™æå‡ / CTF / æ¨ªå‘ç§»åŠ¨ / æŒä¹…åŒ– / é˜²å¾¡æ£€æµ‹ç­‰è§’åº¦æ·±å…¥åˆ†æï¼Œéœ€æ˜ç¡®æ ‡æ³¨é£é™©ç­‰çº§ï¼‰

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
ï¼ˆç»™å‡º 3 ä¸ªå…¸å‹åœºæ™¯ç¤ºä¾‹ï¼Œå®‰å…¨ä¸é€šç”¨å„æœ‰æ¶‰åŠï¼‰

---
å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€ç²¾å‡†ï¼Œé€‚åˆç»ˆç«¯é˜…è¯»ã€‚"""

SYSTEM_SECURITY = """\
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„çº¢é˜Ÿæ¸—é€æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äº Linux/Kali å‘½ä»¤çš„å®‰å…¨åº”ç”¨ä¸æ¼æ´åˆ©ç”¨ã€‚
ç”¨æˆ·ç»™ä½ ä¸€æ¡å‘½ä»¤ï¼Œè¯·ä»ä»¥ä¸‹å®‰å…¨è§’åº¦æ·±å…¥åˆ†æï¼ˆå…¨éƒ¨ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šç²¾å‡†ï¼‰ï¼š

## ğŸ“‹ å‘½ä»¤æ¦‚è§ˆ
ï¼ˆæ ¸å¿ƒåŠŸèƒ½ç®€è¿°ï¼Œä¸€å¥è¯ï¼‰

## ğŸ”´ å®‰å…¨æ·±åº¦åˆ†æ

### æ”»å‡»é¢ä¸åˆ©ç”¨ä»·å€¼
- æƒé™æå‡ï¼ˆPrivilege Escalationï¼‰æ€è·¯ä¸åˆ©ç”¨æ¡ä»¶
- æ¨ªå‘ç§»åŠ¨ / ä¿¡æ¯æ”¶é›† / æŒä¹…åŒ–å¯èƒ½æ€§
- GTFOBins æ”¶å½•æƒ…å†µï¼ˆå¦‚é€‚ç”¨ï¼Œç»™å‡ºå…·ä½“åˆ©ç”¨å‘½ä»¤ï¼‰

### CTF & çœŸå®æ¸—é€åœºæ™¯
ï¼ˆæè¿°å…¸å‹åˆ©ç”¨é“¾ã€ç»•è¿‡æ‰‹æ³•ã€å¸¸è§å‡ºé¢˜åœºæ™¯ï¼‰

### é£é™©ç­‰çº§è¯„ä¼°
| ç»´åº¦ | è¯„çº§ | è¯´æ˜ |
|------|------|------|
| æƒé™æå‡é£é™© | ğŸ”´é«˜/ğŸŸ¡ä¸­/ğŸŸ¢ä½ | ... |
| æŒä¹…åŒ–é£é™©   | ğŸ”´é«˜/ğŸŸ¡ä¸­/ğŸŸ¢ä½ | ... |
| ä¿¡æ¯æ³„éœ²é£é™© | ğŸ”´é«˜/ğŸŸ¡ä¸­/ğŸŸ¢ä½ | ... |

## ğŸ›¡ï¸ é˜²å¾¡ä¸æ£€æµ‹ï¼ˆè“é˜Ÿè§†è§’ï¼‰
ï¼ˆå¦‚ä½•ç›‘æ§ã€å‘Šè­¦æˆ–ç¼“è§£æ­¤å‘½ä»¤çš„æ»¥ç”¨ï¼ŒåŒ…æ‹¬ auditd è§„åˆ™ã€SIEM å‘Šè­¦æ€è·¯ç­‰ï¼‰

## ğŸ’¡ åˆ©ç”¨ç¤ºä¾‹
ï¼ˆ2-3 ä¸ªçº¢é˜Ÿ / CTF çœŸå®æˆ–ç»å…¸åœºæ™¯ç¤ºä¾‹ï¼‰

---
ä¸“ä¸šç²¾å‡†ï¼Œé€‚åˆçº¢è“å¯¹æŠ—å‚è€ƒã€‚"""

SYSTEM_GENERAL = """\
ä½ æ˜¯ä¸€åèµ„æ·± Linux ç³»ç»Ÿç®¡ç†å‘˜å’Œ DevOps å·¥ç¨‹å¸ˆã€‚
ç”¨æˆ·ç»™ä½ ä¸€æ¡å‘½ä»¤ï¼Œè¯·ä»ä»¥ä¸‹è§’åº¦ç³»ç»Ÿè§£é‡Šï¼ˆå…¨éƒ¨ç”¨ä¸­æ–‡ï¼Œé€šä¿—æ˜“æ‡‚ï¼‰ï¼š

## ğŸ“‹ å‘½ä»¤æ¦‚è§ˆ
ï¼ˆæ ¸å¿ƒåŠŸèƒ½ç®€è¿°ï¼Œ1-2 å¥è¯ï¼‰

## ğŸ”© å‚æ•°è§£æ
ï¼ˆç”¨è¡¨æ ¼åˆ—å‡ºæ¯ä¸ªå‚æ•° / é€‰é¡¹çš„å«ä¹‰ï¼‰

## ğŸ”§ ä½¿ç”¨åœºæ™¯
ï¼ˆæ—¥å¸¸è¿ç»´ã€å¼€å‘ã€è„šæœ¬è‡ªåŠ¨åŒ–ä¸­çš„å…¸å‹ç”¨é€”ï¼Œè‡³å°‘ 3 ä¸ªåœºæ™¯ï¼‰

## âš ï¸ æ³¨æ„äº‹é¡¹
ï¼ˆå¸¸è§é”™è¯¯ã€æ€§èƒ½é™·é˜±ã€æƒé™è¦æ±‚ã€è·¨å‘è¡Œç‰ˆå·®å¼‚ç­‰ï¼‰

## ğŸ”„ ç±»ä¼¼å‘½ä»¤å¯¹æ¯”
ï¼ˆä¸åŠŸèƒ½ç›¸è¿‘å‘½ä»¤çš„ç®€è¦å¯¹æ¯”ï¼Œå¸®åŠ©é€‰æ‹©ï¼‰

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
ï¼ˆ3 ä¸ªç”±æµ…å…¥æ·±çš„å…¸å‹ç¤ºä¾‹ï¼‰

---
è¯­è¨€é€šä¿—ï¼Œé€‚åˆæœ‰ä¸€å®š Linux åŸºç¡€çš„å·¥ç¨‹å¸ˆé˜…è¯»ã€‚"""

# â”€â”€ English prompts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_BOTH_EN = """\
You are an expert consultant proficient in both Linux system administration and cybersecurity (penetration testing / CTF).
The user will provide a Linux/Kali command (possibly with flags and target paths).
Reply strictly in the following Markdown structure, in English:

## ğŸ“‹ Overview
(1-2 sentences describing the core function of the command)

## ğŸ”© Parameter Breakdown
(Table or list explaining each option / flag / argument in the command)

## ğŸ”§ General Perspective
(Typical uses from a sysadmin, DevOps, or developer angle â€” best practices and caveats)

## ğŸ”´ Security Perspective
(Deep analysis from a pentesting / privilege escalation / CTF / lateral movement / persistence / blue-team detection angle â€” include risk level)

## ğŸ’¡ Usage Examples
(3 typical examples covering both security and general scenarios)

---
Respond entirely in English. Be precise and terminal-friendly."""

SYSTEM_SECURITY_EN = """\
You are an experienced red-team penetration tester focused on the security applications and exploitation of Linux/Kali commands.
Analyze the provided command from the following security angles, entirely in English:

## ğŸ“‹ Overview
(One-sentence core function summary)

## ğŸ”´ Security Deep Dive

### Attack Surface & Exploitation Value
- Privilege Escalation (PrivEsc) potential and conditions
- Lateral movement / reconnaissance / persistence possibilities
- GTFOBins listing (if applicable â€” provide exact exploit commands)

### CTF & Real-World Pentest Scenarios
(Describe typical exploit chains, bypass techniques, common CTF patterns)

### Risk Assessment
| Dimension | Level | Notes |
|-----------|-------|-------|
| Privilege Escalation | ğŸ”´High/ğŸŸ¡Med/ğŸŸ¢Low | ... |
| Persistence Risk     | ğŸ”´High/ğŸŸ¡Med/ğŸŸ¢Low | ... |
| Information Leakage  | ğŸ”´High/ğŸŸ¡Med/ğŸŸ¢Low | ... |

## ğŸ›¡ï¸ Defense & Detection (Blue-Team View)
(How to monitor, alert on, or mitigate abuse of this command â€” auditd rules, SIEM logic, etc.)

## ğŸ’¡ Exploitation Examples
(2-3 red-team / CTF classic or real-world examples)

---
Professional and precise, suitable for red/blue team reference."""

SYSTEM_GENERAL_EN = """\
You are a senior Linux system administrator and DevOps engineer.
Explain the provided command from the following angles, entirely in English:

## ğŸ“‹ Overview
(1-2 sentence core function summary)

## ğŸ”© Parameter Breakdown
(Table listing each flag / option and its meaning)

## ğŸ”§ Use Cases
(Typical uses in daily operations, development, and shell scripting â€” at least 3 scenarios)

## âš ï¸ Caveats & Best Practices
(Common mistakes, performance pitfalls, permission requirements, cross-distro differences)

## ğŸ”„ Similar Commands
(Brief comparison with functionally similar commands to help choose the right tool)

## ğŸ’¡ Usage Examples
(3 examples ranging from basic to advanced)

---
Clear and accessible for engineers with some Linux experience."""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å½©è‰²è¾“å‡ºï¼ˆrich å¯é€‰ï¼Œè‡ªåŠ¨é™çº§ä¸ºçº¯æ–‡æœ¬ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.markdown import Markdown
    console = Console()
    HAS_RICH = True
except ImportError:
    HAS_RICH = False
    console = None


def _print_header(command: str, mode: str, lang: str = "zh"):
    mode_labels_zh = {
        "both":     "å…¨è§†è§’ï¼ˆé€šç”¨ + å®‰å…¨ï¼‰",
        "security": "ğŸ”´ å®‰å…¨è§†è§’ï¼ˆæ¸—é€ / CTF / çº¢é˜Ÿï¼‰",
        "general":  "ğŸ”§ é€šç”¨è§†è§’ï¼ˆç³»ç»Ÿç®¡ç† / è¿ç»´ï¼‰",
    }
    mode_labels_en = {
        "both":     "Full View (General + Security)",
        "security": "ğŸ”´ Security View (Pentest / CTF / Red Team)",
        "general":  "ğŸ”§ General View (Sysadmin / DevOps)",
    }
    labels = mode_labels_en if lang == "en" else mode_labels_zh
    label = labels.get(mode, mode)
    cmd_prefix = "Command" if lang == "en" else "å‘½ä»¤"
    mode_prefix = "Mode" if lang == "en" else "æ¨¡å¼"
    if HAS_RICH:
        console.print()
        console.print(Panel(
            f"[bold yellow]$ {command}[/bold yellow]\n[dim]{label}[/dim]",
            title="[bold cyan]ğŸ” Explain Tool[/bold cyan]",
            border_style="bright_blue",
            padding=(0, 2),
        ))
    else:
        sep = "=" * 60
        print(f"\n{sep}")
        print(f"  {cmd_prefix}: {command}")
        print(f"  {mode_prefix}: {label}")
        print(f"{sep}\n")


def _print_result(content: str):
    if HAS_RICH:
        console.print(Markdown(content))
        console.print()
    else:
        print(content)
        print()


def _print_error(msg: str):
    if HAS_RICH:
        console.print(f"[bold red]âœ— é”™è¯¯ï¼š[/bold red]{msg}")
    else:
        print(f"[é”™è¯¯] {msg}", file=sys.stderr)


def _print_info(msg: str):
    if HAS_RICH:
        console.print(f"[dim]  â³ {msg}[/dim]")
    else:
        print(f"  >> {msg}")


def _print_success(msg: str):
    if HAS_RICH:
        console.print(f"[green]  âœ“ {msg}[/green]")
    else:
        print(f"  [OK] {msg}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é…ç½®
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_config() -> Dict[str, Any]:
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            merged = DEFAULT_CONFIG.copy()
            merged.update(cfg)
            return merged
        except Exception:
            pass
    return DEFAULT_CONFIG.copy()


def save_config(cfg: Dict[str, Any]):
    CONFIG_DIR.mkdir(parents=True, exist_ok=True)
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(cfg, f, indent=2, ensure_ascii=False)


def run_config_wizard():
    cfg = load_config()

    if HAS_RICH:
        console.print(Panel("[bold]Explain Tool â€” é…ç½®å‘å¯¼[/bold]", border_style="cyan"))
    else:
        print("\n=== Explain Tool é…ç½®å‘å¯¼ ===\n")

    backends = ["openai", "ollama", "deepseek", "custom"]
    print("\nå¯ç”¨åç«¯ï¼š")
    for i, b in enumerate(backends, 1):
        marker = " â† å½“å‰" if b == cfg["backend"] else ""
        print(f"  {i}. {b}{marker}")

    choice = input(f"\né€‰æ‹©åç«¯ç¼–å· [å›è½¦ä¿æŒä¸å˜]: ").strip()
    if choice.isdigit() and 1 <= int(choice) <= len(backends):
        cfg["backend"] = backends[int(choice) - 1]

    if cfg["backend"] == "ollama":
        host = input(f"Ollama åœ°å€ [{cfg['ollama_host']}]: ").strip()
        if host:
            cfg["ollama_host"] = host
        model = input(f"Ollama æ¨¡å‹ [{cfg['ollama_model']}]: ").strip()
        if model:
            cfg["ollama_model"] = model
    else:
        # è‡ªåŠ¨é…ç½®å¸¸è§åç«¯
        if cfg["backend"] == "deepseek":
            cfg["api_base"] = "https://api.deepseek.com/v1"
            cfg.setdefault("model", "deepseek-chat")
            if cfg.get("model") == "gpt-4o-mini":
                cfg["model"] = "deepseek-chat"
        elif cfg["backend"] == "custom":
            api_base = input(f"API Base URL [{cfg['api_base']}]: ").strip()
            if api_base:
                cfg["api_base"] = api_base
            model = input(f"æ¨¡å‹åç§° [{cfg['model']}]: ").strip()
            if model:
                cfg["model"] = model

        api_key = input(f"API Key [{'å·²è®¾ç½®ï¼Œå›è½¦ä¿æŒ' if cfg['api_key'] else 'è¯·è¾“å…¥'}]: ").strip()
        if api_key:
            cfg["api_key"] = api_key

        if cfg["backend"] in ("openai", "custom"):
            model = input(f"æ¨¡å‹åç§° [{cfg['model']}]: ").strip()
            if model:
                cfg["model"] = model

    # è¯­è¨€é€‰æ‹©
    print("\nå›å¤è¯­è¨€ / Response Languageï¼š")
    lang_options = list(SUPPORTED_LANGUAGES.items())
    for i, (code, name) in enumerate(lang_options, 1):
        marker = " â† å½“å‰ / current" if code == cfg.get("language", "zh") else ""
        print(f"  {i}. {code}  {name}{marker}")
    lang_choice = input("\né€‰æ‹©è¯­è¨€ç¼–å· / Select language [å›è½¦ä¿æŒ / Enter to keep]: ").strip()
    if lang_choice.isdigit() and 1 <= int(lang_choice) <= len(lang_options):
        cfg["language"] = lang_options[int(lang_choice) - 1][0]

    cache_choice = input(f"\nå¯ç”¨ç»“æœç¼“å­˜ï¼Ÿ[{'y' if cfg['cache'] else 'n'}, å›è½¦ä¿æŒ]: ").strip().lower()
    if cache_choice == "y":
        cfg["cache"] = True
    elif cache_choice == "n":
        cfg["cache"] = False

    save_config(cfg)
    _print_success(f"é…ç½®å·²ä¿å­˜ â†’ {CONFIG_FILE}")
    print(f"\nå½“å‰åç«¯: {cfg['backend']}")
    if cfg["backend"] == "ollama":
        print(f"  Ollama: {cfg['ollama_host']}  æ¨¡å‹: {cfg['ollama_model']}")
    else:
        print(f"  API Base: {cfg['api_base']}")
        print(f"  æ¨¡å‹: {cfg['model']}")
        print(f"  API Key: {'å·²è®¾ç½®' if cfg['api_key'] else 'âš ï¸  æœªè®¾ç½®'}")
    lang_code = cfg.get("language", "zh")
    print(f"  è¯­è¨€ / Language: {lang_code}ï¼ˆ{SUPPORTED_LANGUAGES.get(lang_code, lang_code)}ï¼‰")
    print()


def show_config(cfg: Dict[str, Any]):
    if HAS_RICH:
        from rich.table import Table
        t = Table(title="å½“å‰é…ç½®", border_style="dim")
        t.add_column("é”®", style="cyan")
        t.add_column("å€¼", style="yellow")
        for k, v in cfg.items():
            display_v = "***ï¼ˆå·²è®¾ç½®ï¼‰" if k == "api_key" and v else str(v)
            t.add_row(k, display_v)
        console.print(t)
    else:
        print("\nå½“å‰é…ç½®ï¼š")
        for k, v in cfg.items():
            display_v = "***ï¼ˆå·²è®¾ç½®ï¼‰" if k == "api_key" and v else str(v)
            print(f"  {k}: {display_v}")
        print()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç¼“å­˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _cache_key(command: str, mode: str, model_id: str, lang: str = "zh") -> str:
    raw = f"{command.strip()}|{mode}|{model_id}|{lang}"
    return hashlib.md5(raw.encode("utf-8")).hexdigest()


def _get_cached(key: str) -> Optional[str]:
    f = CACHE_DIR / f"{key}.md"
    if f.exists():
        try:
            return f.read_text(encoding="utf-8")
        except Exception:
            pass
    return None


def _set_cache(key: str, content: str):
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    try:
        (CACHE_DIR / f"{key}.md").write_text(content, encoding="utf-8")
    except Exception:
        pass


def clear_cache():
    if CACHE_DIR.exists():
        count = len(list(CACHE_DIR.glob("*.md")))
        shutil.rmtree(CACHE_DIR)
        _print_success(f"å·²æ¸…ç©ºç¼“å­˜ï¼ˆå…± {count} æ¡è®°å½•ï¼‰")
    else:
        _print_info("ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM API è°ƒç”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _http_post(url: str, payload: dict, headers: dict, timeout: int = 120) -> dict:
    """é€šç”¨ HTTP POSTï¼Œä½¿ç”¨æ ‡å‡†åº“ urllibï¼ˆæ— éœ€ requestsï¼‰"""
    data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
    req = urllib.request.Request(url, data=data, headers=headers, method="POST")
    with urllib.request.urlopen(req, timeout=timeout) as resp:
        return json.loads(resp.read().decode("utf-8"))


def _call_openai_compat(
    api_base: str, api_key: str, model: str,
    system_prompt: str, user_message: str
) -> str:
    url = f"{api_base.rstrip('/')}/chat/completions"
    headers = {
        "Content-Type":  "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": user_message},
        ],
        "temperature": 0.2,
        "max_tokens":  2048,
    }
    data = _http_post(url, payload, headers)
    return data["choices"][0]["message"]["content"]


def _call_ollama(
    host: str, model: str,
    system_prompt: str, user_message: str
) -> str:
    url = f"{host.rstrip('/')}/api/chat"
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": user_message},
        ],
        "stream":  False,
        "options": {"temperature": 0.2},
    }
    data = _http_post(url, payload, headers, timeout=180)
    return data["message"]["content"]


def _query_llm(cfg: Dict[str, Any], system_prompt: str, command: str, lang: str = "zh") -> str:
    if lang == "en":
        user_msg = (
            f"Please explain the following Linux/Kali command â€” its purpose, parameters, and usage scenarios:\n\n"
            f"```\n{command}\n```"
        )
    else:
        user_msg = (
            f"è¯·è§£é‡Šä»¥ä¸‹ Linux/Kali å‘½ä»¤çš„ä½œç”¨å«ä¹‰å’Œä½¿ç”¨åœºæ™¯ï¼š\n\n"
            f"```\n{command}\n```"
        )
    backend = cfg.get("backend", "openai")

    if backend == "ollama":
        return _call_ollama(
            cfg["ollama_host"], cfg["ollama_model"],
            system_prompt, user_msg
        )
    else:
        api_key = cfg.get("api_key", "").strip()
        if not api_key:
            raise ValueError(
                "API Key æœªé…ç½®ï¼è¯·è¿è¡Œ explain --config è¿›è¡Œé…ç½®ï¼Œ\n"
                "  æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ EXPLAIN_API_KEY=<your-key>"
            )
        return _call_openai_compat(
            cfg["api_base"], api_key, cfg["model"],
            system_prompt, user_msg
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ ¸å¿ƒé€»è¾‘
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_PROMPTS = {
    "zh": {
        "both":     SYSTEM_BOTH,
        "security": SYSTEM_SECURITY,
        "general":  SYSTEM_GENERAL,
    },
    "en": {
        "both":     SYSTEM_BOTH_EN,
        "security": SYSTEM_SECURITY_EN,
        "general":  SYSTEM_GENERAL_EN,
    },
}


def explain_command(
    command: str,
    mode: str,
    cfg: Dict[str, Any],
    no_cache: bool = False,
):
    lang = cfg.get("language", "zh")
    # ä¸æ”¯æŒçš„è¯­è¨€ä»£ç å›é€€åˆ°ä¸­æ–‡
    prompts = _PROMPTS.get(lang, _PROMPTS["zh"])
    system_prompt = prompts[mode]

    model_id = (
        cfg.get("ollama_model") if cfg.get("backend") == "ollama"
        else cfg.get("model", "unknown")
    )
    key = _cache_key(command, mode, model_id, lang)

    # â”€â”€ æ£€æŸ¥ç¼“å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cfg.get("cache", True) and not no_cache:
        cached = _get_cached(key)
        if cached is not None:
            _print_header(command, mode, lang)
            if HAS_RICH:
                cache_hint = "From cache (use -n to force refresh)" if lang == "en" else "æ¥è‡ªç¼“å­˜ï¼ˆä½¿ç”¨ -n å¯å¼ºåˆ¶åˆ·æ–°ï¼‰"
                console.print(f"[dim]  ğŸ’¾ {cache_hint}[/dim]\n")
            _print_result(cached)
            return

    # â”€â”€ è°ƒç”¨ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _print_header(command, mode, lang)
    querying_msg = "Querying, please waitâ€¦" if lang == "en" else "æ­£åœ¨æŸ¥è¯¢ï¼Œè¯·ç¨å€™â€¦"
    _print_info(querying_msg)

    try:
        result = _query_llm(cfg, system_prompt, command, lang)
    except ValueError as e:
        _print_error(str(e))
        sys.exit(1)
    except urllib.error.HTTPError as e:
        body = ""
        try:
            body = e.read().decode("utf-8")
        except Exception:
            pass
        _print_error(f"HTTP {e.code}: {e.reason}\n{body[:300]}")
        sys.exit(1)
    except urllib.error.URLError as e:
        err_prefix = "Network error" if lang == "en" else "ç½‘ç»œè¯·æ±‚å¤±è´¥"
        _print_error(f"{err_prefix}: {e.reason}")
        sys.exit(1)
    except Exception as e:
        err_prefix = "Unexpected error" if lang == "en" else "æœªçŸ¥é”™è¯¯"
        _print_error(f"{err_prefix}: {e}")
        sys.exit(1)

    # â”€â”€ è¾“å‡º & ç¼“å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if HAS_RICH:
        console.print()
    _print_result(result)

    if cfg.get("cache", True) and not no_cache:
        _set_cache(key, result)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI å…¥å£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        prog="explain",
        description=(
            "Kali/Ubuntu å‘½ä»¤è¡Œè§£é‡Šå·¥å…· â€” åŒè§†è§’ï¼ˆå®‰å…¨ + é€šç”¨ï¼‰\n"
            "æ”¯æŒ OpenAI / DeepSeek / Ollama æœ¬åœ°æ¨¡å‹"
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ç¤ºä¾‹ / Examples:
  explain chmod u+s /bin/bash
  explain -s find / -perm -4000 2>/dev/null
  explain -g tar -czf archive.tar.gz /etc
  explain -sg nmap -sV -O 192.168.1.1
  explain --lang en chmod u+s /bin/bash     # English output
  explain --lang zh -s sudo -l              # ä¸­æ–‡å®‰å…¨è§†è§’
  explain --config
  explain --show-config
  explain --clear-cache""",
    )

    # è§†è§’æ ‡å¿—ï¼ˆå¯ä»¥åŒæ—¶åŠ  -s å’Œ -gï¼Œç­‰ä»·äºä¸åŠ ä»»ä½•æ ‡å¿—ï¼‰
    parser.add_argument(
        "-s", "--security",
        action="store_true",
        help="æ˜¾ç¤ºå®‰å…¨è§†è§’ï¼ˆæ¸—é€æµ‹è¯• / CTF / çº¢é˜Ÿï¼‰",
    )
    parser.add_argument(
        "-g", "--general",
        action="store_true",
        help="æ˜¾ç¤ºé€šç”¨è§†è§’ï¼ˆç³»ç»Ÿç®¡ç† / è¿ç»´ï¼‰",
    )
    parser.add_argument(
        "-n", "--no-cache",
        action="store_true",
        help="å¿½ç•¥ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æŸ¥è¯¢ / ignore cache, force re-query",
    )
    parser.add_argument(
        "--lang",
        choices=list(SUPPORTED_LANGUAGES.keys()),
        metavar="LANG",
        help="å›å¤è¯­è¨€ï¼šzhï¼ˆä¸­æ–‡ï¼Œé»˜è®¤ï¼‰/ enï¼ˆEnglishï¼‰ï¼›ä¸´æ—¶è¦†ç›–é…ç½®ï¼Œä»…æœ¬æ¬¡æœ‰æ•ˆ",
    )
    parser.add_argument(
        "--backend",
        choices=["openai", "ollama", "deepseek", "custom"],
        help="ä¸´æ—¶æŒ‡å®š LLM åç«¯ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼Œä»…æœ¬æ¬¡æœ‰æ•ˆï¼‰",
    )
    parser.add_argument(
        "--config",
        action="store_true",
        help="è¿è¡Œäº¤äº’å¼é…ç½®å‘å¯¼ / run interactive config wizard",
    )
    parser.add_argument(
        "--show-config",
        action="store_true",
        help="æ˜¾ç¤ºå½“å‰é…ç½® / show current config",
    )
    parser.add_argument(
        "--clear-cache",
        action="store_true",
        help="æ¸…ç©ºæœ¬åœ°æŸ¥è¯¢ç¼“å­˜ / clear local query cache",
    )
    parser.add_argument(
        "command",
        nargs="*",
        help="è¦è§£é‡Šçš„å‘½ä»¤ï¼ˆå«å‚æ•°ï¼‰",
    )

    args = parser.parse_args()

    # â”€â”€ åŠŸèƒ½å‹å­å‘½ä»¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.config:
        run_config_wizard()
        return

    if args.show_config:
        show_config(load_config())
        return

    if args.clear_cache:
        clear_cache()
        return

    if not args.command:
        parser.print_help()
        print(
            "\næç¤ºï¼šé¦–æ¬¡ä½¿ç”¨è¯·å…ˆè¿è¡Œ explain --config é…ç½® LLM åç«¯\n"
            "      æœ¬åœ°æ—  API Key å¯é€‰æ‹© Ollamaï¼ˆéœ€æœ¬åœ°è¿è¡Œ Ollamaï¼‰\n"
        )
        sys.exit(0)

    # â”€â”€ ç¡®å®šè§£é‡Šæ¨¡å¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä¸¤ä¸ªéƒ½é€‰æˆ–éƒ½ä¸é€‰ â†’ å…¨è§†è§’
    if args.security and args.general:
        mode = "both"
    elif args.security:
        mode = "security"
    elif args.general:
        mode = "general"
    else:
        mode = "both"

    command_str = " ".join(args.command)

    # â”€â”€ åŠ è½½é…ç½®ï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cfg = load_config()

    # ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§æœ€é«˜
    env_key = os.environ.get("EXPLAIN_API_KEY", "").strip()
    if env_key:
        cfg["api_key"] = env_key
    env_base = os.environ.get("EXPLAIN_API_BASE", "").strip()
    if env_base:
        cfg["api_base"] = env_base
    env_model = os.environ.get("EXPLAIN_MODEL", "").strip()
    if env_model:
        cfg["model"] = env_model
    env_lang = os.environ.get("EXPLAIN_LANG", "").strip().lower()
    if env_lang in SUPPORTED_LANGUAGES:
        cfg["language"] = env_lang

    # CLI å‚æ•°ä¸´æ—¶è¦†ç›–ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    if args.lang:
        cfg["language"] = args.lang
    if args.backend:
        cfg["backend"] = args.backend
        if args.backend == "deepseek":
            cfg["api_base"] = "https://api.deepseek.com/v1"
            if cfg.get("model") in ("gpt-4o-mini", ""):
                cfg["model"] = "deepseek-chat"

    explain_command(command_str, mode, cfg, no_cache=args.no_cache)


if __name__ == "__main__":
    main()
